{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "# df = pd.read_csv('../data/greek_fake_news.csv')\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df.replace(to_replace='[\\n\\r\\t]', value=' ', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_data, limit=0, split=0.8):\n",
    "    random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{\"REAL\": not bool(y), \"FAKE\": bool(y)} for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    \n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if label == \"FAKE\":\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.0\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.0\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 99 entries, 0 to 98\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    99 non-null     object\n",
      " 1   text     99 non-null     object\n",
      " 2   source   94 non-null     object\n",
      " 3   url      99 non-null     object\n",
      " 4   is_fake  99 non-null     int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['tagger', 'parser', 'ner', 'textcat']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat=nlp.create_pipe( \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"})\n",
    "nlp.add_pipe(textcat, last=True)\n",
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat.add_label(\"REAL\")\n",
    "textcat.add_label(\"FAKE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tuples'] = df.apply(lambda row: (row['text'], row['is_fake']), axis=1)\n",
    "train = df['tuples'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(train, split=0.9)\n",
    "\n",
    "train_data = list(zip(train_texts,[{'cats': cats} for cats in train_cats]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "0.932\t0.625\t1.000\t0.769\n",
      "0.440\t0.625\t1.000\t0.769\n",
      "0.141\t1.000\t1.000\t1.000\n",
      "0.039\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.002\t1.000\t1.000\t1.000\n",
      "0.005\t1.000\t1.000\t1.000\n",
      "0.018\t1.000\t1.000\t1.000\n",
      "0.147\t1.000\t1.000\t1.000\n",
      "0.064\t1.000\t1.000\t1.000\n",
      "0.044\t1.000\t1.000\t1.000\n",
      "0.001\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n",
      "0.000\t1.000\t1.000\t1.000\n"
     ]
    }
   ],
   "source": [
    "n_iter = 20\n",
    "# Disabling other components\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "\n",
    "    print(\"Training the model...\")\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "\n",
    "    # Performing training\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n",
    "                       losses=losses)\n",
    "\n",
    "      # Calling the evaluate() function and printing the scores\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "        print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  \n",
    "              .format(losses['textcat'], scores['textcat_p'],\n",
    "                      scores['textcat_r'], scores['textcat_f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'REAL': 0.9876824021339417, 'FAKE': 0.012317556887865067}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '''\n",
    "The 12 members of the breakaway Super League are meeting to discuss the future of the exclusive competition, according to multiple reports on Tuesday.\n",
    "\n",
    "TalkSPORT was the first to report news of the meeting. CNN has reached out to the Super League for comment but has not heard back.\n",
    "Earlier on Tuesday, a number of clubs, including Chelsea and Manchester City, were reportedly preparing to leave the newly announced European Super League competition\n",
    "According to multiple reports on Tuesday, including The Athletic and Sky News, Chelsea was preparing documents to formally withdraw from the exclusive group of 12 clubs.\n",
    "Later on Tuesday, The Sun newspaper reported Manchester City was also pulling out.\n",
    "CNN Sport has reached out to Chelsea and Manchester City about the reports but has not heard back.\n",
    "On Sunday, six English clubs -- Arsenal, Chelsea, Liverpool, Manchester City, Manchester United, and Tottenham Hotspur -- alongside three teams from Italy -- AC Milan, Inter Milan and Juventus -- and three from Spain -- Atl√©tico Madrid, Barcelona and Real Madrid -- had laid out plans to form the breakaway competition.\n",
    "'''\n",
    "\n",
    "doc = nlp(test)\n",
    "doc.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nlp.use_params(optimizer.averages):\n",
    "            nlp.to_disk('../model')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}